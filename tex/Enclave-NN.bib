
@inproceedings{chu_best_2016,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Best {Practices} for {Fine}-{Tuning} {Visual} {Classifiers} to {New} {Domains}},
	isbn = {978-3-319-49409-8},
	doi = {10.1007/978-3-319-49409-8_34},
	abstract = {Recent studies have shown that features from deep convolutional neural networks learned using large labeled datasets, like ImageNet, provide effective representations for a variety of visual recognition tasks. They achieve strong performance as generic features and are even more effective when fine-tuned to target datasets. However, details of the fine-tuning procedure across datasets and with different amount of labeled data are not well-studied and choosing the best fine-tuning method is often left to trial and error. In this work we systematically explore the design-space for fine-tuning and give recommendations based on two key characteristics of the target dataset: visual distance from source dataset and the amount of available training data. Through a comprehensive experimental analysis, we conclude, with a few exceptions, that it is best to copy as many layers of a pre-trained network as possible, and then adjust the level of fine-tuning based on the visual distance from source.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2016 {Workshops}},
	publisher = {Springer International Publishing},
	author = {Chu, Brian and Madhavan, Vashisht and Beijbom, Oscar and Hoffman, Judy and Darrell, Trevor},
	editor = {Hua, Gang and Jégou, Hervé},
	year = {2016},
	pages = {435--442},
	file = {Springer Full Text PDF:/home/alex/Zotero/storage/V3ECRBMI/Chu et al. - 2016 - Best Practices for Fine-Tuning Visual Classifiers .pdf:application/pdf}
}

@inproceedings{zeiler_visualizing_2014,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Visualizing and {Understanding} {Convolutional} {Networks}},
	isbn = {978-3-319-10590-1},
	doi = {10.1007/978-3-319-10590-1_53},
	abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark Krizhevsky et al. [18]. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we explore both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. Used in a diagnostic role, these visualizations allow us to find model architectures that outperform Krizhevsky et al on the ImageNet classification benchmark. We also perform an ablation study to discover the performance contribution from different model layers. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
	language = {en},
	booktitle = {Computer {Vision} – {ECCV} 2014},
	publisher = {Springer International Publishing},
	author = {Zeiler, Matthew D. and Fergus, Rob},
	editor = {Fleet, David and Pajdla, Tomas and Schiele, Bernt and Tuytelaars, Tinne},
	year = {2014},
	keywords = {Convolutional Neural Network, Input Image, Pixel Space, Stochastic Gradient Descent, Training Image},
	pages = {818--833},
	file = {Springer Full Text PDF:/home/alex/Zotero/storage/TNGLTBAM/Zeiler and Fergus - 2014 - Visualizing and Understanding Convolutional Networ.pdf:application/pdf}
}

@article{simonyan_very_2015,
	title = {Very {Deep} {Convolutional} {Networks} for {Large}-{Scale} {Image} {Recognition}},
	url = {http://arxiv.org/abs/1409.1556},
	abstract = {In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting. Our main contribution is a thorough evaluation of networks of increasing depth using an architecture with very small (3x3) convolution filters, which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers. These findings were the basis of our ImageNet Challenge 2014 submission, where our team secured the first and the second places in the localisation and classification tracks respectively. We also show that our representations generalise well to other datasets, where they achieve state-of-the-art results. We have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual representations in computer vision.},
	urldate = {2020-02-10},
	journal = {arXiv:1409.1556 [cs]},
	author = {Simonyan, Karen and Zisserman, Andrew},
	month = apr,
	year = {2015},
	note = {arXiv: 1409.1556},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	file = {arXiv.org Snapshot:/home/alex/Zotero/storage/R9YQIZAD/1409.html:text/html;arXiv Fulltext PDF:/home/alex/Zotero/storage/ZXNC5GUT/Simonyan and Zisserman - 2015 - Very Deep Convolutional Networks for Large-Scale I.pdf:application/pdf}
}

@article{roth_deep_2016,
	title = {Deep {Convolutional} {Neural} {Networks} for {Computer}-{Aided} {Detection}: {CNN} {Architectures}, {Dataset} {Characteristics} and {Transfer} {Learning}},
	volume = {35},
	issn = {1558-254X},
	shorttitle = {Deep {Convolutional} {Neural} {Networks} for {Computer}-{Aided} {Detection}},
	doi = {10.1109/TMI.2016.2528162},
	abstract = {Remarkable progress has been made in image recognition, primarily due to the availability of large-scale annotated datasets and deep convolutional neural networks (CNNs). CNNs enable learning data-driven, highly representative, hierarchical image features from sufficient training data. However, obtaining datasets as comprehensively annotated as ImageNet in the medical imaging domain remains a challenge. There are currently three major techniques that successfully employ CNNs to medical image classification: training the CNN from scratch, using off-the-shelf pre-trained CNN features, and conducting unsupervised CNN pre-training with supervised fine-tuning. Another effective method is transfer learning, i.e., fine-tuning CNN models pre-trained from natural image dataset to medical image tasks. In this paper, we exploit three important, but previously understudied factors of employing deep convolutional neural networks to computer-aided detection problems. We first explore and evaluate different CNN architectures. The studied models contain 5 thousand to 160 million parameters, and vary in numbers of layers. We then evaluate the influence of dataset scale and spatial image context on performance. Finally, we examine when and why transfer learning from pre-trained ImageNet (via fine-tuning) can be useful. We study two specific computer-aided detection (CADe) problems, namely thoraco-abdominal lymph node (LN) detection and interstitial lung disease (ILD) classification. We achieve the state-of-the-art performance on the mediastinal LN detection, and report the first five-fold cross-validation classification results on predicting axial CT slices with ILD categories. Our extensive empirical evaluation, CNN model analysis and valuable insights can be extended to the design of high performance CAD systems for other medical imaging tasks.},
	number = {5},
	journal = {IEEE Transactions on Medical Imaging},
	author = {Roth, Holger R. and Gao, Mingchen and Lu, Le and Xu, Ziyue and Nogues, Isabella and Yao, Jianhua and Mollura, Daniel and Summers, Ronald M.},
	month = may,
	year = {2016},
	keywords = {axial CT slices, Biomedical imaging, CNN architectures, CNN model analysis, Computational modeling, Computed tomography, computer aided diagnosis, computer-aided detection, computer-aided detection problems, computerised tomography, Databases, Factual, dataset characteristics, deep convolutional neural networks, Diagnosis, Computer-Assisted, diseases, Diseases, fine-tuning CNN models, five-fold cross-validation classification, high performance CAD systems, highly representative hierarchical image features, Humans, image analysis, image classification, Image Interpretation, Computer-Assisted, image recognition, image representation, interstitial lung disease classification, learning (artificial intelligence), learning data-driven, lung, Lung Diseases, Interstitial, Lungs, Lymph nodes, Lymph Nodes, machine learning, mediastinal LN detection, medical image classification, medical image processing, medical image tasks, medical imaging domain, natural image dataset, neural networks, Neural Networks (Computer), neurophysiology, off-the-shelf pretrained CNN features, pretrained imagenet, Reproducibility of Results, reviews, Solid modeling, spatial image context, state-of-the-art performance, supervised fine-tuning, thoraco-abdominal lymph node detection, transfer learning, unsupervised CNN pretraining},
	pages = {1285--1298},
	file = {Accepted Version:/home/alex/Zotero/storage/9DBLH7H8/Shin et al. - 2016 - Deep Convolutional Neural Networks for Computer-Ai.pdf:application/pdf;IEEE Xplore Abstract Record:/home/alex/Zotero/storage/7RX6NJKJ/7404017.html:text/html}
}

@incollection{zhou_learning_2014,
	title = {Learning {Deep} {Features} for {Scene} {Recognition} using {Places} {Database}},
	url = {http://papers.nips.cc/paper/5349-learning-deep-features-for-scene-recognition-using-places-database.pdf},
	booktitle = {Advances in {Neural} {Information} {Processing} {Systems} 27},
	publisher = {Curran Associates, Inc.},
	author = {Zhou, Bolei and Lapedriza, Agata and Xiao, Jianxiong and Torralba, Antonio and Oliva, Aude},
	editor = {Ghahramani, Z. and Welling, M. and Cortes, C. and Lawrence, N. D. and Weinberger, K. Q.},
	year = {2014},
	pages = {487--495},
	file = {Zhou et al_2014_Learning Deep Features for Scene Recognition using Places Database.pdf:/home/alex/Zotero/storage/NHUDSTZT/Zhou et al_2014_Learning Deep Features for Scene Recognition using Places Database.pdf:application/pdf}
}

@inproceedings{tramer_stealing_2016,
	title = {Stealing {Machine} {Learning} {Models} via {Prediction} {APIs}},
	isbn = {978-1-931971-32-4},
	url = {https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/tramer},
	language = {en},
	urldate = {2020-02-12},
	author = {Tramèr, Florian and Zhang, Fan and Juels, Ari and Reiter, Michael K. and Ristenpart, Thomas},
	year = {2016},
	pages = {601--618},
	file = {Tramèr et al_2016_Stealing Machine Learning Models via Prediction APIs.pdf:/home/alex/Zotero/storage/L8ECHNF9/Tramèr et al_2016_Stealing Machine Learning Models via Prediction APIs.pdf:application/pdf}
}

@inproceedings{shokri_membership_2017,
	title = {Membership {Inference} {Attacks} {Against} {Machine} {Learning} {Models}},
	doi = {10.1109/SP.2017.41},
	abstract = {We quantitatively investigate how machine learning models leak information about the individual data records on which they were trained. We focus on the basic membership inference attack: given a data record and black-box access to a model, determine if the record was in the model's training dataset. To perform membership inference against a target model, we make adversarial use of machine learning and train our own inference model to recognize differences in the target model's predictions on the inputs that it trained on versus the inputs that it did not train on. We empirically evaluate our inference techniques on classification models trained by commercial "machine learning as a service" providers such as Google and Amazon. Using realistic datasets and classification tasks, including a hospital discharge dataset whose membership is sensitive from the privacy perspective, we show that these models can be vulnerable to membership inference attacks. We then investigate the factors that influence this leakage and evaluate mitigation strategies.},
	booktitle = {2017 {IEEE} {Symposium} on {Security} and {Privacy} ({SP})},
	author = {Shokri, Reza and Stronati, Marco and Song, Congzheng and Shmatikov, Vitaly},
	month = may,
	year = {2017},
	note = {ISSN: 2375-1207},
	keywords = {adversarial use, authorisation, black-box access, classification models, Data models, data privacy, data record, Google, hospital discharge dataset, hospitals, inference mechanisms, inference techniques, learning (artificial intelligence), machine learning models, membership inference attacks, pattern classification, Predictive models, Privacy, privacy perspective, Sociology, Statistics, Training},
	pages = {3--18},
	file = {Shokri et al_2017_Membership Inference Attacks Against Machine Learning Models.pdf:/home/alex/Zotero/storage/G8G4C3CD/Shokri et al_2017_Membership Inference Attacks Against Machine Learning Models.pdf:application/pdf;IEEE Xplore Abstract Record:/home/alex/Zotero/storage/E2RI2I87/7958568.html:text/html}
}

@inproceedings{shokri_privacy-preserving_2015,
	address = {Denver, Colorado, USA},
	series = {{CCS} '15},
	title = {Privacy-{Preserving} {Deep} {Learning}},
	isbn = {978-1-4503-3832-5},
	url = {https://doi.org/10.1145/2810103.2813687},
	doi = {10.1145/2810103.2813687},
	abstract = {Deep learning based on artificial neural networks is a very popular approach to modeling, classifying, and recognizing complex data such as images, speech, and text. The unprecedented accuracy of deep learning methods has turned them into the foundation of new AI-based services on the Internet. Commercial companies that collect user data on a large scale have been the main beneficiaries of this trend since the success of deep learning techniques is directly proportional to the amount of data available for training. Massive data collection required for deep learning presents obvious privacy issues. Users' personal, highly sensitive data such as photos and voice recordings is kept indefinitely by the companies that collect it. Users can neither delete it, nor restrict the purposes for which it is used. Furthermore, centrally kept data is subject to legal subpoenas and extra-judicial surveillance. Many data owners--for example, medical institutions that may want to apply deep learning methods to clinical records--are prevented by privacy and confidentiality concerns from sharing the data and thus benefitting from large-scale deep learning. In this paper, we design, implement, and evaluate a practical system that enables multiple parties to jointly learn an accurate neural-network model for a given objective without sharing their input datasets. We exploit the fact that the optimization algorithms used in modern deep learning, namely, those based on stochastic gradient descent, can be parallelized and executed asynchronously. Our system lets participants train independently on their own datasets and selectively share small subsets of their models' key parameters during training. This offers an attractive point in the utility/privacy tradeoff space: participants preserve the privacy of their respective data while still benefitting from other participants' models and thus boosting their learning accuracy beyond what is achievable solely on their own inputs. We demonstrate the accuracy of our privacy-preserving deep learning on benchmark datasets.},
	urldate = {2020-02-12},
	booktitle = {Proceedings of the 22nd {ACM} {SIGSAC} {Conference} on {Computer} and {Communications} {Security}},
	publisher = {Association for Computing Machinery},
	author = {Shokri, Reza and Shmatikov, Vitaly},
	month = oct,
	year = {2015},
	keywords = {deep learning, gradient descent, neural networks, privacy},
	pages = {1310--1321},
	file = {Shokri_Shmatikov_2015_Privacy-Preserving Deep Learning.pdf:/home/alex/Zotero/storage/3L2USWHT/Shokri_Shmatikov_2015_Privacy-Preserving Deep Learning.pdf:application/pdf}
}

@inproceedings{ohrimenko_oblivious_2016,
	title = {Oblivious {Multi}-{Party} {Machine} {Learning} on {Trusted} {Processors}},
	isbn = {978-1-931971-32-4},
	url = {https://www.usenix.org/conference/usenixsecurity16/technical-sessions/presentation/ohrimenko},
	language = {en},
	urldate = {2020-02-12},
	author = {Ohrimenko, Olga and Schuster, Felix and Fournet, Cédric and Mehta, Aastha and Nowozin, Sebastian and Vaswani, Kapil and Costa, Manuel},
	year = {2016},
	pages = {619--636},
	file = {Ohrimenko et al_2016_Oblivious Multi-Party Machine Learning on Trusted Processors.pdf:/home/alex/Zotero/storage/JRI6GA27/Ohrimenko et al_2016_Oblivious Multi-Party Machine Learning on Trusted Processors.pdf:application/pdf}
}

@inproceedings{papernot_practical_2017,
	address = {Abu Dhabi, United Arab Emirates},
	title = {Practical {Black}-{Box} {Attacks} against {Machine} {Learning}},
	isbn = {978-1-4503-4944-4},
	url = {http://dl.acm.org/citation.cfm?doid=3052973.3053009},
	doi = {10.1145/3052973.3053009},
	abstract = {Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modiﬁed to yield erroneous model outputs, while appearing unmodiﬁed to human observers. Potential attacks include having malicious content like malware identiﬁed as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the ﬁrst practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and ﬁnd that they are misclassiﬁed by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We ﬁnd that their DNN misclassiﬁes 84.24\% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassiﬁed by Amazon and Google at rates of 96.19\% and 88.94\%. We also ﬁnd that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.},
	language = {en},
	urldate = {2020-02-12},
	booktitle = {Proceedings of the 2017 {ACM} on {Asia} {Conference} on {Computer} and {Communications} {Security} - {ASIA} {CCS} '17},
	publisher = {ACM Press},
	author = {Papernot, Nicolas and McDaniel, Patrick and Goodfellow, Ian and Jha, Somesh and Celik, Z. Berkay and Swami, Ananthram},
	year = {2017},
	pages = {506--519},
	file = {Papernot et al. - 2017 - Practical Black-Box Attacks against Machine Learni.pdf:/home/alex/Zotero/storage/EG3GYC2B/Papernot et al. - 2017 - Practical Black-Box Attacks against Machine Learni.pdf:application/pdf}
}

@article{tramer_slalom_2019,
	title = {Slalom: {Fast}, {Verifiable} and {Private} {Execution} of {Neural} {Networks} in {Trusted} {Hardware}},
	shorttitle = {Slalom},
	url = {http://arxiv.org/abs/1806.03287},
	abstract = {As Machine Learning (ML) gets applied to security-critical or sensitive domains, there is a growing need for integrity and privacy for outsourced ML computations. A pragmatic solution comes from Trusted Execution Environments (TEEs), which use hardware and software protections to isolate sensitive computations from the untrusted software stack. However, these isolation guarantees come at a price in performance, compared to untrusted alternatives. This paper initiates the study of high performance execution of Deep Neural Networks (DNNs) in TEEs by efficiently partitioning DNN computations between trusted and untrusted devices. Building upon an efficient outsourcing scheme for matrix multiplication, we propose Slalom, a framework that securely delegates execution of all linear layers in a DNN from a TEE (e.g., Intel SGX or Sanctum) to a faster, yet untrusted, co-located processor. We evaluate Slalom by running DNNs in an Intel SGX enclave, which selectively delegates work to an untrusted GPU. For canonical DNNs (VGG16, MobileNet and ResNet variants) we obtain 6x to 20x increases in throughput for verifiable inference, and 4x to 11x for verifiable and private inference.},
	urldate = {2020-02-12},
	journal = {arXiv:1806.03287 [cs, stat]},
	author = {Tramèr, Florian and Boneh, Dan},
	month = feb,
	year = {2019},
	note = {arXiv: 1806.03287},
	keywords = {Computer Science - Cryptography and Security, Computer Science - Machine Learning, Statistics - Machine Learning},
	file = {Tramèr_Boneh_2019_Slalom.pdf:/home/alex/Zotero/storage/QQZ4KCT6/Tramèr_Boneh_2019_Slalom.pdf:application/pdf;arXiv.org Snapshot:/home/alex/Zotero/storage/QNX8SNBZ/1806.html:text/html}
}

@article{kaptchuk_giving_nodate,
	title = {Giving {State} to the {Stateless}: {Augmenting} {Trustworthy} {Computation} with {Ledgers}},
	abstract = {In this work we investigate the problem of achieving secure computation by combining stateless trusted devices with public ledgers. We consider a hybrid paradigm in which a client-side device (such as a co-processor or trusted enclave) performs secure computation, while interacting with a public ledger via a possibly malicious host computer. We explore both the constructive and potentially destructive implications of such systems. We ﬁrst show that this combination allows for the construction of stateful interactive functionalities (including general computation) even when the device has no persistent storage; this allows us to build sophisticated applications using inexpensive trusted hardware or even pure cryptographic obfuscation techniques. We further show how to use this paradigm to achieve censorshipresistant communication with a network, even when network communications are mediated by a potentially malicious host. Finally we describe a number of practical applications that can be achieved today. These include the synchronization of private smart contracts; rate limited mandatory logging; strong encrypted backups from weak passwords; enforcing fairness in multi-party computation; and destructive applications such as autonomous ransomware, which allows for payments without an online party.},
	language = {en},
	author = {Kaptchuk, Gabriel and Miers, Ian and Green, Matthew},
	pages = {35},
	file = {Kaptchuk et al. - Giving State to the Stateless Augmenting Trustwor.pdf:/home/alex/Zotero/storage/SF3GM7QG/Kaptchuk et al. - Giving State to the Stateless Augmenting Trustwor.pdf:application/pdf}
}